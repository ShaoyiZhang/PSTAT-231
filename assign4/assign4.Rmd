---
title: "assign4"
author: "Shaoyi Zhang"
date: "May 24, 2016"
output: html_document
---
```{r global_options, include=FALSE,warning=F}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',warning=FALSE)
```

```{r}
setwd("/Users/Shawn/Desktop/PSTAT 231/PSTAT-231/assign4")
set.seed(2)
library(data.table)
#food.data = data.table()
food.data = read.table("food.txt",header = T,row.names = 1)
#for (i in 2:6){
#  food.data[,c(i)] = as.numeric(food.data[,c(i)])
#}

```

```{r}
library(ggplot2)
#km.out = kmeans(food.data[2:6], centers = 3, nstart = 20)
##str(km.out$centers)
#list(km.out$size)

maxK = 10
centroids = list()
cluster.size = list()
#for (k in 2:maxK){
  km.2 = kmeans(food.data[2:ncol(food.data)], centers = 2, iter.max = 10, nstart = 20)
  centroids[k-1] = km.out$centers
  cluster.size[k-1] = list(km.out$size)
#}
centroids
km.out$centers
#maxK = nrow(st.food)-1
#maxK = 10
st.food=scale(food.data[c(1:5)])
# k- means clustering loop
ratiowss=vector()
for (k in 2:maxK){
  km=kmeans(st.food,k,nstart=50)
  ratiowss[k]=km$tot.withinss/km$totss
}
dt=data.table("K"=2:maxK,"ratiowss"=ratiowss[2:maxK])
ggplot(dt,aes(x=K,y=ratiowss))+geom_line(size=3)
```

Since there are only 27 data points in this data set, I think the number of clusters shouldn't be too large. Moreover, by PCA, I noticed that the first 4 principle components expained more than 99% of the variance in the data. Thus, I decide to use K = 4 for further analysis

```{r}
# use clusters = 4 for further analysis
km.out = kmeans(st.food,centers = 4)
centers = data.table(km.out$centers)
```

Let's take a look at the centers of the clusters

```{r}
centers
# transpose to make it more readable
tCenters = t(centers)
which.max(tCenters[1,])

maxims=vector()
for (i in 1:nrow(tCenters)){
  maxims[i]=which.max(tCenters[i,])
  print(which.max(tCenters[i,]))
}
maxims
```

```{r}
centers[,Group:=as.factor(c(1,2,3,4))]
library(GGally)
gpd <- ggparcoord(data = centers, columns = 1:5, groupColumn = 6)
gpd
```

According to the parallel coordinate plot of the centroids, we noticed that:

Group 1 has high Calcium and very low Iron.

Group 2 has high Protein and low Calcium.

Group 3 has very low Protein, energy and fat, and very high Calcium and Iron.

Group 4 has very high Energy and Fat, but very low Calcium.


```{r,echo=F}
# food.data = as.data.table(food.data,keep.rownames = T)
# food.data[,"Cluster":=as.factor(km.out$cluster)]
# gg2=ggplot(food.data,aes(x=X1,y=X2,color=Cluster,shape=Group,))+geom_point(size=3)
# gg2+geom_point(aes(x=km.out$center[1,1],y=km.out$center[1,2]),size=4,color="black")+geom_point(aes(x=km.out$center[2,1],y=km.out$center[2,2]),size=4,color="black")+ annotate("text", x=km.out$center[1,1],y=km.out$center[1,2]-0.2, label = "Centroid 1")+ annotate("text", x=km.out$center[2,1],y=km.out$center[2,2]-0.2, label = "Centroid 2")+ggtitle("k-means clustering, k=2")+ theme(plot.title = element_text(size = rel(2)))
```

```{r}
pr.out = prcomp(food.data[1:5], center = T, scale=T)
summary(pr.out)
# The first 4 PC explained 99.97% of the variance
library(ggbiplot)

# Use ggbiplot to create PCA graph
ggbiplot(pr.out, obs.scale = 1, var.scale = 1, 
         ellipse = TRUE, circle = TRUE) +
  scale_color_discrete(name = '') +
  theme(legend.direction = 'horizontal', legend.position = 'top')

pr.out
```



```{r}
# compute distance matrix
dist.food = dist(st.food)

library(gridExtra)

cluster.single = hclust(dist.food,method = "single")
plot(cluster.single)

cluster.complete = hclust(dist.food,method = "complete")
plot(cluster.complete)

cluster.average = hclust(dist.food,method = "average")
plot(cluster.average)
```


